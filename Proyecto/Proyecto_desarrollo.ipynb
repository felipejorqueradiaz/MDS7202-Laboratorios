{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cbbdd29",
   "metadata": {
    "cell_id": "00006-84a35c5d-0758-4cbb-b2ca-b182898b80d0",
    "deepnote_cell_height": 295.8833312988281,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "\n",
    "# Proyecto\n",
    "\n",
    "### Equipo:\n",
    "\n",
    "- Felipe Jorquera Díaz\n",
    "\n",
    "- \\<Nombre de usuarios en Codalab\\>\n",
    "\n",
    "- \\<Nombre del Equipo en Codalab\\>\n",
    "\n",
    "### Link de repositorio de GitHub: `https://github.com/felipejorqueradiaz`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585563b4",
   "metadata": {
    "cell_id": "00007-447f1977-318e-432f-ba83-12d7e667ae68",
    "deepnote_cell_height": 253.13333129882812,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "## 1. Introducción\n",
    "\n",
    "El objetivo de este proyecto consiste en ...\n",
    "\n",
    "Los datos que proveen es un dataset con X ejemplos que describen una observación de ... \n",
    "Son N atributos y la variables objetivos son de tipo ... y ...\n",
    "\n",
    "La primera tarea se evalua en base a la métrica ... ya que esta permite medir ...\n",
    "\n",
    "Nuestra propuesta para resolver el problema consistió en modelo de clasificación basado en...\n",
    "\n",
    "Nuestro modelo cumplió/no cumplió las expectativas..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7922658",
   "metadata": {
    "cell_id": "00008-6607fdcd-a35f-4e75-9b46-da3b181c1551",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "## 2. Prepración y Análisis Exploratorio de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2522db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "#pip install pyarrow\n",
    "#pip install seaborn\n",
    "#pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.pickle', \"rb\") as fh:\n",
    "    data_val = pickle.load(fh)\n",
    "data_val['tipo'] = 'val' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d7c22bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a999640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_parquet('train_numerical_features.parquet')\n",
    "data2 = pd.read_parquet('train_text_features.parquet')  \n",
    "                           \n",
    "data = data1.merge(data2, on = ['id', 'tagline', 'credits', 'title'])\n",
    "data['tipo'] = 'traintest'\n",
    "                           \n",
    "data = pd.concat([data, data_val], axis=0)\n",
    "                           \n",
    "data.drop(['poster_path', 'backdrop_path', 'recommendations'], axis=1, inplace=True)\n",
    "\n",
    "data = data[~ (\n",
    "    (data['revenue']==0) |\n",
    "    (data['release_date'].isna()) |\n",
    "    (data['runtime'].isna()) |\n",
    "    ((data['status'] != 'Released'))\n",
    "                )]\n",
    "\n",
    "data['release_date'] = pd.to_datetime(data['release_date'], format = '%Y-%m-%d')\n",
    "\n",
    "data_cat = data.select_dtypes(include=[object])\n",
    "data[data_cat.columns] = data_cat.fillna('')\n",
    "\n",
    "data.loc[(data['vote_average'] <= 10) & (data['vote_average'] > 8), 'label'] = 'Very Positive'\n",
    "data.loc[(data['vote_average'] <= 8) & (data['vote_average'] > 7), 'label'] = 'Positive'\n",
    "data.loc[(data['vote_average'] <= 7) & (data['vote_average'] > 6), 'label'] = 'Mostly Positive'\n",
    "data.loc[(data['vote_average'] <= 6) & (data['vote_average'] > 5), 'label'] = 'Mixed'\n",
    "data.loc[(data['vote_average'] <= 5) , 'label'] = 'Negative'\n",
    "\n",
    "data.drop(['vote_average', 'id', 'status'], axis=1, inplace=True)\n",
    "data.rename(columns = {'revenue':'target'},\n",
    "            inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "9dce6e4c",
   "metadata": {
    "cell_id": "00009-e413acae-3cf7-44db-847c-b846e3673adc",
    "deepnote_cell_height": 80.13333129882812,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166425,
    "source_hash": "55969c6e"
   },
   "outputs": [],
   "source": [
    "##  Código Preparación de Datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f6852b2d",
   "metadata": {
    "cell_id": "051fb133d1264c4dab1de21415aa18b6",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Código EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132fb1f",
   "metadata": {
    "cell_id": "6dfb65f58341449fb33eb025db788790",
    "deepnote_cell_height": 69.93333435058594,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "```\n",
    "Análisis del EDA.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7780b9",
   "metadata": {
    "cell_id": "00011-95957584-71f1-4669-a6e5-9b8ac7b8d4e0",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Preprocesamiento, Holdout y Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a3ef91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "c9ea4205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data['day'] = data['release_date'].dt.day\n",
    "data['month'] = data['release_date'].dt.month\n",
    "data['year'] = data['release_date'].dt.year\n",
    "data['day_name'] = data['release_date'].dt.day_name()\n",
    "\n",
    "data['en_language'] = np.where(data['original_language'] == 'en', 1, 0)\n",
    "\n",
    "data['log_budget'] = np.log(data['budget'])\n",
    "data['log_budget'].replace(np.inf, 0, inplace=True)\n",
    "data['log_budget'].replace(-np.inf, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "88f15206",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['genres', 'credits', 'production_companies']:\n",
    "    values = [x.split(sep='-') for x in data[col]]\n",
    "    len_values = [len(x) for x in values]\n",
    "    data[f'len_{col}'] = len_values\n",
    "    \n",
    "    '''\n",
    "    values = [i for x in values for i in x]\n",
    "    val_unique, counts = np.unique(values, return_counts=True)\n",
    "    series_count = pd.Series(counts, index = val_unique).sort_values(ascending = False).head(10)\n",
    "    \n",
    "    for value in series_count.index:\n",
    "        data[f'{col}_{value}'] = pd.DataFrame(np.where(dataframe[col].str.contains(col), 1, 0))\n",
    "    \n",
    "    df_final = pd.concat(df.values(), axis=1)\n",
    "    df_final.columns = df.keys()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "92a68509",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_genres = ['Drama', 'Action', 'Comedy', 'Adventure', 'Thriller',\n",
    "                 'Fantasy', 'Science Fiction', 'Family', 'Crime', 'Romance']\n",
    "for pop in popular_genres:\n",
    "    data[f'genre_{pop}'] = pd.DataFrame(np.where(data['genres'].str.contains(pop), 1, 0))\n",
    "    \n",
    "data['genre_Other'] = data.loc[:,data.columns[-len(popular_genres):]].sum(1)\n",
    "data['genre_Popular'] = np.where(data['genre_Other']>0, 1, 0)\n",
    "data['genre_Other'] = np.where(data['genre_Other']==0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "0513a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "actores = [x.split(sep='-') for x in data['production_companies']]\n",
    "values = [i for x in actores for i in x]\n",
    "val_unique, counts = np.unique(values, return_counts=True)\n",
    "series_count = pd.Series(counts, index = val_unique).sort_values(ascending = False).head(50)\n",
    "\n",
    "counter2 = np.zeros(len(data))\n",
    "for pop in series_count.index:\n",
    "    counter2 = counter2 + np.where(data['production_companies'].str.contains(pop), 1, 0)\n",
    "data['Popular_company'] = counter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a613db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actores = [x.split(sep='-') for x in data['credits']]\n",
    "values = [i for x in actores for i in x]\n",
    "val_unique, counts = np.unique(values, return_counts=True)\n",
    "series_count = pd.Series(counts, index = val_unique).sort_values(ascending = False).head(150)\n",
    "\n",
    "counter2 = np.zeros(len(data))\n",
    "for pop in series_count.index:\n",
    "    counter2 = counter2 + np.where(data['credits'].str.contains(pop), 1, 0)\n",
    "data['Popular_actor'] = counter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "312bbed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Felipe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize  \n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "3e0fe037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Felipe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e0b0a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seteamos el idioma en inglés\n",
    "stop_words = stopwords.words('spanish')\n",
    "\n",
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
    "        return [self.ps.stem(t) for t in doc_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "bdfd39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "57224f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>budget</th>\n",
       "      <th>target</th>\n",
       "      <th>runtime</th>\n",
       "      <th>tagline</th>\n",
       "      <th>credits</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Fantasy</th>\n",
       "      <th>genre_Science Fiction</th>\n",
       "      <th>genre_Family</th>\n",
       "      <th>genre_Crime</th>\n",
       "      <th>genre_Romance</th>\n",
       "      <th>genre_Other</th>\n",
       "      <th>genre_Popular</th>\n",
       "      <th>Popular_company</th>\n",
       "      <th>Popular_actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fantastic Beasts: The Secrets of Dumbledore</td>\n",
       "      <td>200000000.0</td>\n",
       "      <td>400000000.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>Return to the magic.</td>\n",
       "      <td>Jude Law-Eddie Redmayne-Mads Mikkelsen-Ezra Mi...</td>\n",
       "      <td>Fantasy-Adventure-Action</td>\n",
       "      <td>Professor Albus Dumbledore knows the powerful ...</td>\n",
       "      <td>Warner Bros. Pictures-Heyday Films</td>\n",
       "      <td>magic-curse-fantasy world-wizard-magical creat...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sonic the Hedgehog 2</td>\n",
       "      <td>110000000.0</td>\n",
       "      <td>393000000.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Welcome to the next level.</td>\n",
       "      <td>James Marsden-Ben Schwartz-Tika Sumpter-Natash...</td>\n",
       "      <td>Action-Adventure-Family-Comedy</td>\n",
       "      <td>After settling in Green Hills Sonic is eager t...</td>\n",
       "      <td>Original Film-Blur Studio-Marza Animation Plan...</td>\n",
       "      <td>sequel-based on video game-hedgehog-live actio...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title       budget       target  \\\n",
       "0  Fantastic Beasts: The Secrets of Dumbledore  200000000.0  400000000.0   \n",
       "1                         Sonic the Hedgehog 2  110000000.0  393000000.0   \n",
       "\n",
       "   runtime                     tagline  \\\n",
       "0    142.0        Return to the magic.   \n",
       "1    122.0  Welcome to the next level.   \n",
       "\n",
       "                                             credits  \\\n",
       "0  Jude Law-Eddie Redmayne-Mads Mikkelsen-Ezra Mi...   \n",
       "1  James Marsden-Ben Schwartz-Tika Sumpter-Natash...   \n",
       "\n",
       "                           genres  \\\n",
       "0        Fantasy-Adventure-Action   \n",
       "1  Action-Adventure-Family-Comedy   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Professor Albus Dumbledore knows the powerful ...   \n",
       "1  After settling in Green Hills Sonic is eager t...   \n",
       "\n",
       "                                production_companies  \\\n",
       "0                 Warner Bros. Pictures-Heyday Films   \n",
       "1  Original Film-Blur Studio-Marza Animation Plan...   \n",
       "\n",
       "                                            keywords  ... genre_Thriller  \\\n",
       "0  magic-curse-fantasy world-wizard-magical creat...  ...            0.0   \n",
       "1  sequel-based on video game-hedgehog-live actio...  ...            0.0   \n",
       "\n",
       "  genre_Fantasy  genre_Science Fiction  genre_Family  genre_Crime  \\\n",
       "0           1.0                    0.0           0.0          0.0   \n",
       "1           0.0                    0.0           1.0          0.0   \n",
       "\n",
       "  genre_Romance  genre_Other  genre_Popular  Popular_company  Popular_actor  \n",
       "0           0.0            0              1              1.0            1.0  \n",
       "1           0.0            0              1              2.0            2.0  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['release_date', 'original_language'], axis=1).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "da2243e0",
   "metadata": {
    "cell_id": "00012-f977f172-2409-44c1-9ff4-118d043985cc",
    "deepnote_cell_height": 80.13333129882812,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166470,
    "source_hash": "2dc8e0f4"
   },
   "outputs": [],
   "source": [
    "## Código Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "16c3cc44",
   "metadata": {
    "cell_id": "00014-3a4f50bf-0f3a-496f-9360-ce23ceaba0cb",
    "deepnote_cell_height": 80.13333129882812,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166470,
    "source_hash": "2dc8e0f4"
   },
   "outputs": [],
   "source": [
    "## Código ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f20ea8e5",
   "metadata": {
    "cell_id": "00016-5586ef61-95ea-4f5a-8ad0-796be8c78ac0",
    "deepnote_cell_height": 80.13333129882812,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166471,
    "source_hash": "2dc8e0f4"
   },
   "outputs": [],
   "source": [
    "## Código Feature Engineering (Opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba28cfd4",
   "metadata": {
    "cell_id": "ec9c0f8a2b044f858858ef3c3248c239",
    "deepnote_cell_height": 102,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "source": [
    "```\n",
    "Comentarios\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b3e46489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e21c6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = ['budget', 'runtime', 'log_budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8ee031b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('StandardScaler', StandardScaler(), col_num),\n",
    "        ('OneHotEncoder', OneHotEncoder(), ['day_name']),\n",
    "        ('BagOfWords1', CountVectorizer(tokenizer= StemmerTokenizer(),\n",
    "                                               ngram_range=(1,2) # Este punto es opcional y es para generar bigramas\n",
    "                                              ), 'title'),\n",
    "        ('BagOfWords2', CountVectorizer(tokenizer= StemmerTokenizer(),\n",
    "                                               ngram_range=(1,2) # Este punto es opcional y es para generar bigramas\n",
    "                                              ), 'overview')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "ff7e8f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'budget', 'target', 'runtime', 'tagline', 'credits', 'genres',\n",
       "       'original_language', 'overview', 'production_companies', 'release_date',\n",
       "       'keywords', 'tipo', 'label', 'day', 'month', 'year', 'day_name',\n",
       "       'en_language', 'log_budget', 'len_genres', 'len_credits',\n",
       "       'len_production_companies', 'genre_Drama', 'genre_Action',\n",
       "       'genre_Comedy', 'genre_Adventure', 'genre_Thriller', 'genre_Fantasy',\n",
       "       'genre_Science Fiction', 'genre_Family', 'genre_Crime', 'genre_Romance',\n",
       "       'genre_Other', 'genre_Popular', 'Popular_company', 'Popular_actor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "783154e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = data[data['tipo'] == 'val'].drop('tipo', axis=1)\n",
    "data = data[data['tipo'] != 'val'].drop('tipo', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "4d67550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(data['label'])\n",
    "data['label'] = le.transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "393129dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['target', 'credits', 'genres',\n",
    "       'original_language', 'production_companies', 'release_date',\n",
    "       'keywords', 'label'], axis=1),\n",
    "    data['label'],\n",
    "    shuffle = True,\n",
    "    test_size = 0.2,\n",
    "    random_state = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550866f",
   "metadata": {
    "cell_id": "00018-d6de5b4a-3ce2-4aaa-9421-121c4fcaf3b5",
    "deepnote_cell_height": 117.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "## 4. Clasificación\n",
    "\n",
    "### 4.1 Dummy y Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e62c437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "52bf5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline(steps = [\n",
    "    ('prepro', preprocessing),\n",
    "    ('model', DecisionTreeClassifier(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e9c80823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c94ec1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el modelo DecisionTree el performance es el siguiente:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.25      0.28       272\n",
      "           1       0.49      0.56      0.52       611\n",
      "           2       0.00      0.00      0.00        31\n",
      "           3       0.38      0.37      0.37       346\n",
      "           4       0.12      0.06      0.08        31\n",
      "\n",
      "    accuracy                           0.42      1291\n",
      "   macro avg       0.26      0.25      0.25      1291\n",
      "weighted avg       0.40      0.42      0.41      1291\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelines = {'DecisionTree': pipe1}\n",
    "\n",
    "for name, model in pipelines.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    scores = classification_report(y_test, y_pred)\n",
    "    print(f'Para el modelo {name} el performance es el siguiente:\\n',scores,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "32049c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_grid = Pipeline(steps = [\n",
    "    ('prepro', preprocessing),\n",
    "    ('modelo', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "974b64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        'modelo': [LogisticRegression(random_state = 0)],\n",
    "        'modelo__penalty': ['l1', 'l2'],\n",
    "        'modelo__solver': ['liblinear'],\n",
    "        'prepro__BagOfWords2__ngram_range': [(1,1), (1,2), (1,3)]\n",
    "    },{\n",
    "        'modelo': [RandomForestClassifier(random_state=0)],\n",
    "        'modelo__max_depth': [2,4,6,8,10],\n",
    "        'prepro__BagOfWords2__ngram_range': [(1,1), (1,2), (1,3)]\n",
    "    },{\n",
    "        'modelo': [xgb.XGBClassifier(random_state=0)],\n",
    "        'prepro__BagOfWords2__ngram_range': [(1,1), (1,2), (1,3)]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bf339a59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5; 1/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 1/5; 1/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.263 total time=   9.2s\n",
      "[CV 2/5; 1/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 2/5; 1/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.241 total time=   9.0s\n",
      "[CV 3/5; 1/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 3/5; 1/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.266 total time=   9.7s\n",
      "[CV 4/5; 1/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 4/5; 1/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.239 total time=   9.3s\n",
      "[CV 5/5; 1/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 5/5; 1/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.242 total time=   9.5s\n",
      "[CV 1/5; 2/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 1/5; 2/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.246 total time=  11.7s\n",
      "[CV 2/5; 2/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 2/5; 2/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.249 total time=  11.6s\n",
      "[CV 3/5; 2/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 3/5; 2/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.253 total time=  11.4s\n",
      "[CV 4/5; 2/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 4/5; 2/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.236 total time=  12.1s\n",
      "[CV 5/5; 2/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 5/5; 2/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.228 total time=  12.6s\n",
      "[CV 1/5; 3/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 1/5; 3/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.246 total time=  14.6s\n",
      "[CV 2/5; 3/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 2/5; 3/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.249 total time=  14.3s\n",
      "[CV 3/5; 3/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 3/5; 3/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.258 total time=  15.5s\n",
      "[CV 4/5; 3/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 4/5; 3/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.236 total time=  15.5s\n",
      "[CV 5/5; 3/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 5/5; 3/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l1, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.225 total time=  16.4s\n",
      "[CV 1/5; 4/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 1/5; 4/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.256 total time=  10.1s\n",
      "[CV 2/5; 4/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 2/5; 4/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.246 total time=  10.9s\n",
      "[CV 3/5; 4/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 3/5; 4/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.253 total time=  11.3s\n",
      "[CV 4/5; 4/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 4/5; 4/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.251 total time=   9.9s\n",
      "[CV 5/5; 4/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 5/5; 4/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.231 total time=  12.4s\n",
      "[CV 1/5; 5/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 1/5; 5/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.240 total time=  12.5s\n",
      "[CV 2/5; 5/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 2/5; 5/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.238 total time=  17.0s\n",
      "[CV 3/5; 5/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 3/5; 5/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.243 total time=  14.1s\n",
      "[CV 4/5; 5/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 4/5; 5/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.237 total time=  15.8s\n",
      "[CV 5/5; 5/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 5/5; 5/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.237 total time=  13.9s\n",
      "[CV 1/5; 6/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.234 total time=  14.9s\n",
      "[CV 2/5; 6/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 2/5; 6/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.242 total time=  14.1s\n",
      "[CV 3/5; 6/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 3/5; 6/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.234 total time=  14.2s\n",
      "[CV 4/5; 6/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 4/5; 6/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.226 total time=  16.9s\n",
      "[CV 5/5; 6/24] START modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 5/5; 6/24] END modelo=LogisticRegression(random_state=0), modelo__penalty=l2, modelo__solver=liblinear, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.236 total time=  14.3s\n",
      "[CV 1/5; 7/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 1/5; 7/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.9s\n",
      "[CV 2/5; 7/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 2/5; 7/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=  10.0s\n",
      "[CV 3/5; 7/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 3/5; 7/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.1s\n",
      "[CV 4/5; 7/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 4/5; 7/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.6s\n",
      "[CV 5/5; 7/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 5/5; 7/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.1s\n",
      "[CV 1/5; 8/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 1/5; 8/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.4s\n",
      "[CV 2/5; 8/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 2/5; 8/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.5s\n",
      "[CV 3/5; 8/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 3/5; 8/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.7s\n",
      "[CV 4/5; 8/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 4/5; 8/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  11.0s\n",
      "[CV 5/5; 8/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 5/5; 8/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.4s\n",
      "[CV 1/5; 9/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 1/5; 9/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  10.8s\n",
      "[CV 2/5; 9/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 2/5; 9/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.7s\n",
      "[CV 3/5; 9/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 3/5; 9/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.4s\n",
      "[CV 4/5; 9/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 4/5; 9/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.5s\n",
      "[CV 5/5; 9/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 5/5; 9/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=2, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  10.7s\n",
      "[CV 1/5; 10/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 1/5; 10/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.7s\n",
      "[CV 2/5; 10/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 2/5; 10/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=  10.5s\n",
      "[CV 3/5; 10/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 3/5; 10/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.2s\n",
      "[CV 4/5; 10/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 4/5; 10/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=  10.7s\n",
      "[CV 5/5; 10/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 5/5; 10/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.8s\n",
      "[CV 1/5; 11/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 1/5; 11/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.5s\n",
      "[CV 2/5; 11/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 2/5; 11/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.4s\n",
      "[CV 3/5; 11/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 3/5; 11/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=   9.6s\n",
      "[CV 4/5; 11/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 11/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.4s\n",
      "[CV 5/5; 11/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 5/5; 11/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.7s\n",
      "[CV 1/5; 12/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 1/5; 12/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.0s\n",
      "[CV 2/5; 12/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 2/5; 12/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.6s\n",
      "[CV 3/5; 12/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 3/5; 12/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.5s\n",
      "[CV 4/5; 12/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 4/5; 12/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.6s\n",
      "[CV 5/5; 12/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 5/5; 12/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=4, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  10.7s\n",
      "[CV 1/5; 13/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 1/5; 13/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.9s\n",
      "[CV 2/5; 13/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 2/5; 13/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.5s\n",
      "[CV 3/5; 13/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 3/5; 13/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.6s\n",
      "[CV 4/5; 13/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 4/5; 13/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=  10.1s\n",
      "[CV 5/5; 13/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 5/5; 13/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.0s\n",
      "[CV 1/5; 14/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 1/5; 14/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.4s\n",
      "[CV 2/5; 14/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 2/5; 14/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.9s\n",
      "[CV 3/5; 14/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 3/5; 14/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=   9.8s\n",
      "[CV 4/5; 14/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 4/5; 14/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.4s\n",
      "[CV 5/5; 14/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 5/5; 14/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.7s\n",
      "[CV 1/5; 15/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 1/5; 15/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  10.8s\n",
      "[CV 2/5; 15/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 2/5; 15/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.8s\n",
      "[CV 3/5; 15/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 3/5; 15/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  13.0s\n",
      "[CV 4/5; 15/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 4/5; 15/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.8s\n",
      "[CV 5/5; 15/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 5/5; 15/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=6, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.4s\n",
      "[CV 1/5; 16/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 1/5; 16/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=  10.0s\n",
      "[CV 2/5; 16/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 2/5; 16/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.7s\n",
      "[CV 3/5; 16/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 3/5; 16/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.4s\n",
      "[CV 4/5; 16/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 4/5; 16/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=  10.2s\n",
      "[CV 5/5; 16/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 5/5; 16/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.9s\n",
      "[CV 1/5; 17/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 1/5; 17/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.9s\n",
      "[CV 2/5; 17/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 2/5; 17/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.6s\n",
      "[CV 3/5; 17/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 17/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=   9.9s\n",
      "[CV 4/5; 17/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 4/5; 17/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.4s\n",
      "[CV 5/5; 17/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 5/5; 17/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.5s\n",
      "[CV 1/5; 18/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 1/5; 18/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.0s\n",
      "[CV 2/5; 18/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 2/5; 18/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.8s\n",
      "[CV 3/5; 18/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 3/5; 18/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.7s\n",
      "[CV 4/5; 18/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 4/5; 18/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.8s\n",
      "[CV 5/5; 18/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 5/5; 18/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=8, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.0s\n",
      "[CV 1/5; 19/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 1/5; 19/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=  10.1s\n",
      "[CV 2/5; 19/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 2/5; 19/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.6s\n",
      "[CV 3/5; 19/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 3/5; 19/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.1s\n",
      "[CV 4/5; 19/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 4/5; 19/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.7s\n",
      "[CV 5/5; 19/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 5/5; 19/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 1);, score=0.126 total time=   9.4s\n",
      "[CV 1/5; 20/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 1/5; 20/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  10.7s\n",
      "[CV 2/5; 20/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 2/5; 20/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  11.1s\n",
      "[CV 3/5; 20/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 3/5; 20/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  11.0s\n",
      "[CV 4/5; 20/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 4/5; 20/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  13.2s\n",
      "[CV 5/5; 20/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 5/5; 20/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 2);, score=0.126 total time=  14.9s\n",
      "[CV 1/5; 21/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 1/5; 21/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  14.4s\n",
      "[CV 2/5; 21/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 2/5; 21/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  12.6s\n",
      "[CV 3/5; 21/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 3/5; 21/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.9s\n",
      "[CV 4/5; 21/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 4/5; 21/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  11.0s\n",
      "[CV 5/5; 21/24] START modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 5/5; 21/24] END modelo=RandomForestClassifier(random_state=0), modelo__max_depth=10, prepro__BagOfWords2__ngram_range=(1, 3);, score=0.126 total time=  12.0s\n",
      "[CV 1/5; 22/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 1/5; 22/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 1);, score=0.243 total time=  17.8s\n",
      "[CV 2/5; 22/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 22/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 1);, score=0.241 total time=  18.2s\n",
      "[CV 3/5; 22/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 3/5; 22/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 1);, score=0.266 total time=  19.0s\n",
      "[CV 4/5; 22/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 4/5; 22/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 1);, score=0.257 total time=  18.2s\n",
      "[CV 5/5; 22/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 1)\n",
      "[CV 5/5; 22/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 1);, score=0.248 total time=  18.2s\n",
      "[CV 1/5; 23/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 1/5; 23/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 2);, score=0.251 total time=  35.8s\n",
      "[CV 2/5; 23/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 23/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 2);, score=0.250 total time=  36.6s\n",
      "[CV 3/5; 23/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 3/5; 23/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 2);, score=0.250 total time=  37.1s\n",
      "[CV 4/5; 23/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 4/5; 23/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 2);, score=0.264 total time=  37.2s\n",
      "[CV 5/5; 23/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 2)\n",
      "[CV 5/5; 23/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 2);, score=0.242 total time=  36.3s\n",
      "[CV 1/5; 24/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 1/5; 24/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 3);, score=0.243 total time= 1.0min\n",
      "[CV 2/5; 24/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 24/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 3);, score=0.246 total time= 1.0min\n",
      "[CV 3/5; 24/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 3/5; 24/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 3);, score=0.255 total time= 1.0min\n",
      "[CV 4/5; 24/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 4/5; 24/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 3);, score=0.273 total time= 1.0min\n",
      "[CV 5/5; 24/24] START modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 3)\n",
      "[CV 5/5; 24/24] END modelo=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=0,\n",
      "              reg_alpha=None, reg_lambda=None, ...), prepro__BagOfWords2__ngram_range=(1, 3);, score=0.245 total time= 1.0min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;prepro&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;StandardScaler&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         [&#x27;budget&#x27;,\n",
       "                                                                          &#x27;runtime&#x27;,\n",
       "                                                                          &#x27;log_budget&#x27;]),\n",
       "                                                                        (&#x27;OneHotEncoder&#x27;,\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         [&#x27;day_name&#x27;]),\n",
       "                                                                        (&#x27;BagOfWords1&#x27;,\n",
       "                                                                         CountVectorizer(ngram_range=(1,\n",
       "                                                                                                      2),\n",
       "                                                                                         tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001DB4DFCC040&gt;),\n",
       "                                                                         &#x27;title&#x27;),\n",
       "                                                                        (&#x27;BagOfWords2&#x27;,\n",
       "                                                                         CountVect...\n",
       "                                                   max_bin=None,\n",
       "                                                   max_cat_to_onehot=None,\n",
       "                                                   max_delta_step=None,\n",
       "                                                   max_depth=None,\n",
       "                                                   max_leaves=None,\n",
       "                                                   min_child_weight=None,\n",
       "                                                   missing=nan,\n",
       "                                                   monotone_constraints=None,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None,\n",
       "                                                   num_parallel_tree=None,\n",
       "                                                   predictor=None,\n",
       "                                                   random_state=0,\n",
       "                                                   reg_alpha=None,\n",
       "                                                   reg_lambda=None, ...)],\n",
       "                          &#x27;prepro__BagOfWords2__ngram_range&#x27;: [(1, 1), (1, 2),\n",
       "                                                               (1, 3)]}],\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;prepro&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;StandardScaler&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         [&#x27;budget&#x27;,\n",
       "                                                                          &#x27;runtime&#x27;,\n",
       "                                                                          &#x27;log_budget&#x27;]),\n",
       "                                                                        (&#x27;OneHotEncoder&#x27;,\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         [&#x27;day_name&#x27;]),\n",
       "                                                                        (&#x27;BagOfWords1&#x27;,\n",
       "                                                                         CountVectorizer(ngram_range=(1,\n",
       "                                                                                                      2),\n",
       "                                                                                         tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001DB4DFCC040&gt;),\n",
       "                                                                         &#x27;title&#x27;),\n",
       "                                                                        (&#x27;BagOfWords2&#x27;,\n",
       "                                                                         CountVect...\n",
       "                                                   max_bin=None,\n",
       "                                                   max_cat_to_onehot=None,\n",
       "                                                   max_delta_step=None,\n",
       "                                                   max_depth=None,\n",
       "                                                   max_leaves=None,\n",
       "                                                   min_child_weight=None,\n",
       "                                                   missing=nan,\n",
       "                                                   monotone_constraints=None,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None,\n",
       "                                                   num_parallel_tree=None,\n",
       "                                                   predictor=None,\n",
       "                                                   random_state=0,\n",
       "                                                   reg_alpha=None,\n",
       "                                                   reg_lambda=None, ...)],\n",
       "                          &#x27;prepro__BagOfWords2__ngram_range&#x27;: [(1, 1), (1, 2),\n",
       "                                                               (1, 3)]}],\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;prepro&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;StandardScaler&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;budget&#x27;, &#x27;runtime&#x27;,\n",
       "                                                   &#x27;log_budget&#x27;]),\n",
       "                                                 (&#x27;OneHotEncoder&#x27;,\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  [&#x27;day_name&#x27;]),\n",
       "                                                 (&#x27;BagOfWords1&#x27;,\n",
       "                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                               2),\n",
       "                                                                  tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001DB4DFCC040&gt;),\n",
       "                                                  &#x27;title&#x27;),\n",
       "                                                 (&#x27;BagOfWords2&#x27;,\n",
       "                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                               2),\n",
       "                                                                  tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001DB5B8574C0&gt;),\n",
       "                                                  &#x27;overview&#x27;)])),\n",
       "                (&#x27;modelo&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">prepro: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;StandardScaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;budget&#x27;, &#x27;runtime&#x27;, &#x27;log_budget&#x27;]),\n",
       "                                (&#x27;OneHotEncoder&#x27;, OneHotEncoder(),\n",
       "                                 [&#x27;day_name&#x27;]),\n",
       "                                (&#x27;BagOfWords1&#x27;,\n",
       "                                 CountVectorizer(ngram_range=(1, 2),\n",
       "                                                 tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001DB4DFCC040&gt;),\n",
       "                                 &#x27;title&#x27;),\n",
       "                                (&#x27;BagOfWords2&#x27;,\n",
       "                                 CountVectorizer(ngram_range=(1, 2),\n",
       "                                                 tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001DB5B8574C0&gt;),\n",
       "                                 &#x27;overview&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;budget&#x27;, &#x27;runtime&#x27;, &#x27;log_budget&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;day_name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BagOfWords1</label><div class=\"sk-toggleable__content\"><pre>title</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2),\n",
       "                tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001DB4DFCC040&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BagOfWords2</label><div class=\"sk-toggleable__content\"><pre>overview</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2),\n",
       "                tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001DB5B8574C0&gt;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('prepro',\n",
       "                                        ColumnTransformer(transformers=[('StandardScaler',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['budget',\n",
       "                                                                          'runtime',\n",
       "                                                                          'log_budget']),\n",
       "                                                                        ('OneHotEncoder',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         ['day_name']),\n",
       "                                                                        ('BagOfWords1',\n",
       "                                                                         CountVectorizer(ngram_range=(1,\n",
       "                                                                                                      2),\n",
       "                                                                                         tokenizer=<__main__.StemmerTokenizer object at 0x000001DB4DFCC040>),\n",
       "                                                                         'title'),\n",
       "                                                                        ('BagOfWords2',\n",
       "                                                                         CountVect...\n",
       "                                                   max_bin=None,\n",
       "                                                   max_cat_to_onehot=None,\n",
       "                                                   max_delta_step=None,\n",
       "                                                   max_depth=None,\n",
       "                                                   max_leaves=None,\n",
       "                                                   min_child_weight=None,\n",
       "                                                   missing=nan,\n",
       "                                                   monotone_constraints=None,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None,\n",
       "                                                   num_parallel_tree=None,\n",
       "                                                   predictor=None,\n",
       "                                                   random_state=0,\n",
       "                                                   reg_alpha=None,\n",
       "                                                   reg_lambda=None, ...)],\n",
       "                          'prepro__BagOfWords2__ngram_range': [(1, 1), (1, 2),\n",
       "                                                               (1, 3)]}],\n",
       "             scoring='f1_macro', verbose=10)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model = GridSearchCV(pipe_grid,\n",
    "                           param_grid=params,\n",
    "                           verbose=10,\n",
    "                            scoring = 'f1_macro',\n",
    "                         cv=5)\n",
    "grid_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8d52589f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.20      0.26       272\n",
      "           1       0.51      0.72      0.60       611\n",
      "           2       0.00      0.00      0.00        31\n",
      "           3       0.46      0.38      0.42       346\n",
      "           4       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.48      1291\n",
      "   macro avg       0.27      0.26      0.25      1291\n",
      "weighted avg       0.44      0.48      0.45      1291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "19b6cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1711f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('grid_model.pickle', 'wb') as handle:\n",
    "    pickle.dump(grid_model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "512ec721",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = grid_model.predict(data_val.drop(['target', 'credits', 'genres',\n",
    "                                       'original_language', 'production_companies', 'release_date',\n",
    "                                       'keywords', 'label'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d0a2e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_val = le.inverse_transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03670a8d",
   "metadata": {
    "cell_id": "00021-c294ef41-853d-4297-b051-d5d4e6577715",
    "deepnote_cell_height": 61.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "### 4.2 Búsqueda del mejor modelo de Clasificación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d679a9",
   "metadata": {
    "cell_id": "00022-b323dc3e-6fa0-4d50-8a50-56ad708178ba",
    "deepnote_cell_height": 80.13333129882812,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166499,
    "source_hash": "8f673430",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Código GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf41f27",
   "metadata": {
    "cell_id": "12d71cdc88dd4c06b9a7e1696853f7b2",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Código Predicción de datos de la competencia aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff12117",
   "metadata": {
    "cell_id": "00023-73786884-e1b2-448a-9636-ab05cf3c1fc5",
    "deepnote_cell_height": 69.93333435058594,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "```\n",
    "Justificación Aquí\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e13a8",
   "metadata": {
    "cell_id": "2d58aececbe34d6184477c8e3cfaa2e3",
    "deepnote_cell_height": 117.69999694824219,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 5. Regresión\n",
    "\n",
    "### 5.1 Dummy y Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e8ccd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(\n",
    "    data.drop(['target', 'tagline', 'credits', 'genres',\n",
    "       'original_language', 'production_companies', 'release_date',\n",
    "       'keywords', 'label'], axis=1),\n",
    "    data['target'],\n",
    "    shuffle = True,\n",
    "    test_size = 0.2,\n",
    "    random_state = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "23662f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>budget</th>\n",
       "      <th>runtime</th>\n",
       "      <th>overview</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day_name</th>\n",
       "      <th>en_language</th>\n",
       "      <th>log_budget</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_Fantasy</th>\n",
       "      <th>genre_Science Fiction</th>\n",
       "      <th>genre_Family</th>\n",
       "      <th>genre_Crime</th>\n",
       "      <th>genre_Romance</th>\n",
       "      <th>genre_Other</th>\n",
       "      <th>genre_Popular</th>\n",
       "      <th>Popular_company</th>\n",
       "      <th>Popular_actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>The Wizard of Oz</td>\n",
       "      <td>2777000.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Young Dorothy finds herself in a magical world...</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>1939</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>14.836882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>Sicko</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>Sicko is a Michael Moore documentary about the...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>16.012735</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>Yves Saint Laurent</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>A look at the life of French designer Yves Sai...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>16.300417</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>Epic</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>A teenager finds herself transported to a deep...</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>18.420681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730</th>\n",
       "      <td>Chasing Amy</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Holden and Banky are comic book artists. Every...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1997</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>12.429216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>The Farewell</td>\n",
       "      <td>250300.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>A headstrong Chinese-American woman returns to...</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>12.430415</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4327</th>\n",
       "      <td>Nutty Professor II: The Klumps</td>\n",
       "      <td>84000000.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>The hilarity begins when professor Sherman Klu...</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2000</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>18.246327</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>The Dictator</td>\n",
       "      <td>65000000.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>The heroic story of a dictator who risks his l...</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>17.989898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>There Will Be Blood</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>Ruthless silver miner turned oil prospector Da...</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>17.034386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>Heroic Losers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>In a town in the Northwest of the province of ...</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5160 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title       budget  runtime  \\\n",
       "1134                The Wizard of Oz    2777000.0    102.0   \n",
       "7190                           Sicko    9000000.0    123.0   \n",
       "8207              Yves Saint Laurent   12000000.0    106.0   \n",
       "1422                            Epic  100000000.0    102.0   \n",
       "6730                     Chasing Amy     250000.0    114.0   \n",
       "...                              ...          ...      ...   \n",
       "6751                    The Farewell     250300.0    100.0   \n",
       "4327  Nutty Professor II: The Klumps   84000000.0    106.0   \n",
       "2140                    The Dictator   65000000.0     83.0   \n",
       "3402             There Will Be Blood   25000000.0    158.0   \n",
       "3579                   Heroic Losers          0.0    116.0   \n",
       "\n",
       "                                               overview  day  month  year  \\\n",
       "1134  Young Dorothy finds herself in a magical world...   15      8  1939   \n",
       "7190  Sicko is a Michael Moore documentary about the...   18      5  2007   \n",
       "8207  A look at the life of French designer Yves Sai...    8      1  2014   \n",
       "1422  A teenager finds herself transported to a deep...   15      5  2013   \n",
       "6730  Holden and Banky are comic book artists. Every...    4      4  1997   \n",
       "...                                                 ...  ...    ...   ...   \n",
       "6751  A headstrong Chinese-American woman returns to...   12      7  2019   \n",
       "4327  The hilarity begins when professor Sherman Klu...   27      7  2000   \n",
       "2140  The heroic story of a dictator who risks his l...   15      5  2012   \n",
       "3402  Ruthless silver miner turned oil prospector Da...   26     12  2007   \n",
       "3579  In a town in the Northwest of the province of ...   15      8  2019   \n",
       "\n",
       "       day_name  en_language  log_budget  ...  genre_Thriller  genre_Fantasy  \\\n",
       "1134    Tuesday            1   14.836882  ...             0.0            1.0   \n",
       "7190     Friday            1   16.012735  ...             NaN            NaN   \n",
       "8207  Wednesday            0   16.300417  ...             NaN            NaN   \n",
       "1422  Wednesday            1   18.420681  ...             0.0            0.0   \n",
       "6730     Friday            1   12.429216  ...             0.0            0.0   \n",
       "...         ...          ...         ...  ...             ...            ...   \n",
       "6751     Friday            1   12.430415  ...             1.0            0.0   \n",
       "4327   Thursday            1   18.246327  ...             1.0            0.0   \n",
       "2140    Tuesday            1   17.989898  ...             0.0            0.0   \n",
       "3402  Wednesday            1   17.034386  ...             0.0            0.0   \n",
       "3579   Thursday            0    0.000000  ...             1.0            0.0   \n",
       "\n",
       "      genre_Science Fiction  genre_Family  genre_Crime  genre_Romance  \\\n",
       "1134                    0.0           0.0          0.0            0.0   \n",
       "7190                    NaN           NaN          NaN            NaN   \n",
       "8207                    NaN           NaN          NaN            NaN   \n",
       "1422                    1.0           0.0          0.0            0.0   \n",
       "6730                    0.0           0.0          0.0            1.0   \n",
       "...                     ...           ...          ...            ...   \n",
       "6751                    1.0           0.0          0.0            0.0   \n",
       "4327                    0.0           0.0          0.0            0.0   \n",
       "2140                    1.0           0.0          0.0            0.0   \n",
       "3402                    0.0           0.0          0.0            0.0   \n",
       "3579                    0.0           0.0          1.0            0.0   \n",
       "\n",
       "      genre_Other  genre_Popular  Popular_company  Popular_actor  \n",
       "1134            0              1              3.0            0.0  \n",
       "7190            1              0              1.0            0.0  \n",
       "8207            1              0              0.0            2.0  \n",
       "1422            0              1              1.0            1.0  \n",
       "6730            0              1              1.0            3.0  \n",
       "...           ...            ...              ...            ...  \n",
       "6751            0              1              0.0            0.0  \n",
       "4327            0              1              2.0            2.0  \n",
       "2140            0              1              1.0            3.0  \n",
       "3402            0              1              2.0            2.0  \n",
       "3579            0              1              0.0            0.0  \n",
       "\n",
       "[5160 rows x 27 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "cbdd2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "091c98bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline(steps = [\n",
    "    ('prepro', preprocessing),\n",
    "    ('model', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "aa6ee37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el modelo OLS el performance es el siguiente:\n",
      " 0.503445240583869 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelines = {'OLS': pipe2}\n",
    "\n",
    "for name, model in pipelines.items():\n",
    "    model.fit(Xr_train, yr_train)\n",
    "    yr_pred = model.predict(Xr_test)\n",
    "    \n",
    "    scores = r2_score(yr_test, yr_pred)\n",
    "    print(f'Para el modelo {name} el performance es el siguiente:\\n',scores,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "55231379",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_val = model.predict(data_val.drop(['target', 'credits', 'genres',\n",
    "                                       'original_language', 'production_companies', 'release_date',\n",
    "                                       'keywords', 'label'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e60ac7",
   "metadata": {
    "cell_id": "86fd465c690a46d1bafed3115c0bceff",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Código Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe48412",
   "metadata": {
    "cell_id": "faaf5b0b0d34479bad168c8dd4cbe508",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Código Regresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aabb6d",
   "metadata": {
    "cell_id": "4e397759bca54254b536d998f20cbd08",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Código Comparación de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58390872",
   "metadata": {
    "cell_id": "23ba7e6c56c841d8b2c11563ca64bf20",
    "deepnote_cell_height": 69.93333435058594,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "```\n",
    "Justificación\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a74e3f7",
   "metadata": {
    "cell_id": "df491c3ed9704211be52235df236b889",
    "deepnote_cell_height": 61.69999694824219,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### 5.2 Búsqueda del mejor modelo de Regresión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede80f38",
   "metadata": {
    "cell_id": "cfc6786c0598444bb8070990453da397",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Código GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6bff5",
   "metadata": {
    "cell_id": "b00b9baef48947d9abcfb6972bdaa3aa",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Código Predicción de datos de la competencia aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba839c6",
   "metadata": {
    "cell_id": "00025-2acf9c12-da85-4c1f-add5-f2b0f600177f",
    "deepnote_cell_height": 69.69999694824219,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "\n",
    "## 6. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e48bbba",
   "metadata": {
    "cell_id": "00026-15c07b20-0e16-48fa-bf3c-33aeb2c4c1db",
    "deepnote_cell_height": 51.53334045410156,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Conclusiones...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dfebeb",
   "metadata": {
    "cell_id": "00027-1e362e1d-a776-4423-93d5-0f568476e4c1",
    "deepnote_cell_height": 84.10000610351562,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Anexo: Generación de Archivo Submit de la Competencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749de65d",
   "metadata": {
    "cell_id": "00028-0a64e7e8-1077-4868-8c96-db3d51323157",
    "deepnote_cell_height": 671.9000244140625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Para subir los resultados obtenidos a la pagina de CodaLab utilice la función `generateFiles` entregada mas abajo. Esto es debido a que usted deberá generar archivos que respeten extrictamente el formato de CodaLab, de lo contario los resultados no se veran reflejados en la pagina de la competencia.\n",
    "\n",
    "Para los resultados obtenidos en su modelo de clasificación y regresión, estos serán guardados en un archivo zip que contenga los archivos `predicctions_clf.txt` para la clasificación y `predicctions_rgr.clf` para la regresión. Los resultados, como se comento antes, deberan ser obtenidos en base al dataset `test.pickle` y en cada una de las lineas deberan presentar las predicciones realizadas.\n",
    "\n",
    "Ejemplos de archivos:\n",
    "\n",
    "- [ ] `predicctions_clf.txt`\n",
    "\n",
    "        Mostly Positive\n",
    "        Mostly Positive\n",
    "        Negative\n",
    "        Positive\n",
    "        Negative\n",
    "        Positive\n",
    "        ...\n",
    "\n",
    "- [ ] `predicctions_rgr.txt`\n",
    "\n",
    "        16103.58\n",
    "        16103.58\n",
    "        16041.89\n",
    "        9328.62\n",
    "        107976.03\n",
    "        194374.08\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "1016c881",
   "metadata": {
    "cell_id": "00029-55f95a4c-2d1f-4354-a690-049fea34bdac",
    "deepnote_cell_height": 620.13330078125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1637954166501,
    "source_hash": "b1cdf32f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "def generateFiles(predict_data, y_pred_clf, y_pred_rgr): #clf_pipe, rgr_pipe):\n",
    "    \"\"\"Genera los archivos a subir en CodaLab\n",
    "\n",
    "    Input\n",
    "    predict_data: Dataframe con los datos de entrada a predecir\n",
    "    clf_pipe: pipeline del clf\n",
    "    rgr_pipe: pipeline del rgr\n",
    "\n",
    "    Ouput\n",
    "    archivo de txt\n",
    "    \"\"\"\n",
    "    #y_pred_clf = clf_pipe.predict(predict_data)\n",
    "    #y_pred_rgr = rgr_pipe.predict(predict_data)\n",
    "    \n",
    "    with open('./predictions_clf.txt', 'w') as f:\n",
    "        for item in y_pred_clf:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with open('./predictions_rgr.txt', 'w') as f:\n",
    "        for item in y_pred_rgr:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with ZipFile('predictions.zip', 'w') as zipObj2:\n",
    "       zipObj2.write('predictions_rgr.txt')\n",
    "       zipObj2.write('predictions_clf.txt')\n",
    "\n",
    "    os.remove(\"predictions_rgr.txt\")\n",
    "    os.remove(\"predictions_clf.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "2bf1da6f",
   "metadata": {
    "cell_id": "b589f659ce2246919e3707e79420aff2",
    "deepnote_cell_height": 138,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ejecutar función para generar el archivo de predicciones.\n",
    "# perdict_data debe tener cargada los datos del text.pickle\n",
    "# mientras que clf_pipe y rgr_pipe, son los pipeline de \n",
    "# clasificación y regresión respectivamente.\n",
    "generateFiles(1, yc_val, yr_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173dca5b",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "dbddc0f3-10b8-4160-bc27-ac993196164c",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
